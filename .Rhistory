install.packages(c("readr", "ggplot2", "tsibble", "lubridate", "ggfortify", "imputeTS"))
# -------------------------------------------
# Part A: Download and understand the dataset
# -------------------------------------------
# Description of the Air Quality dataset:
#
# The dataset contains 9358 instances of hourly averaged responses
# from an array of chemical sensors embedded in an Air Quality
# Chemical Multisensor device.
#
# The dataset has 15 columns:
# 1. Date: Measurement date
# 2. Time: Measurement time
# 3. CO(GT): Carbon Monoxide concentration in ppm (ground truth)
# 4. PT08.S1(CO): Sensor 1, Tin Oxide response related to CO
# 5. NMHC(GT): Non-Methane Hydrocarbons concentration in micrograms/m³
# 6. C6H6(GT): Benzene concentration in micrograms/m³
# 7. PT08.S2(NMHC): Sensor 2, response related to Non-Methane Hydrocarbons
# 8. NOx(GT): Nitrogen Oxides concentration in parts per billion (ground truth)
# 9. PT08.S3(NOx): Sensor 3, response related to NOx
# 10. NO2(GT): Nitrogen Dioxide concentration in parts per billion
# 11. PT08.S4(NO2): Sensor 4, response related to NO2
# 12. PT08.S5(O3): Sensor 5, response related to O3 (Ozone)
# 13. T: Temperature in Celsius
# 14. RH: Relative Humidity (%)
# 15. AH: Absolute Humidity (g/m³)
#
# -------------------------------------------
# Part B: Import and visualize
# -------------------------------------------
#
## Load required libraries
library(readr)
library(ggplot2)
library(tsibble)
library(lubridate)
library(tidyr)  # for pivot_longer
library(dplyr)  # for data manipulation
# 1. Read the dataset
data <- read.table("AirQualityUCI.csv", sep = ";", header = TRUE, na.strings = "-200")
# 2. Clean column names to remove special characters
colnames(data) <- make.names(colnames(data), unique = TRUE)
# Print cleaned column names to verify
print(colnames(data))
# 3. Convert 'Date' and 'Time' columns to POSIXct DateTime format
data$DateTime <- as.POSIXct(paste(data$Date, data$Time), format="%d/%m/%Y %H.%M.%S")
# 4. Remove incomplete rows (e.g., remove rows with NA values in DateTime)
data <- data[complete.cases(data$DateTime), ]
# 5. Convert sensor columns to numeric (handle invalid data as NA)
sensor_columns <- c("CO.GT.", "PT08.S1.CO.", "NMHC.GT.", "C6H6.GT.",
"PT08.S2.NMHC.", "NOx.GT.", "PT08.S3.NOx.",
"NO2.GT.", "PT08.S4.NO2.", "PT08.S5.O3.", "T", "RH", "AH")
data[sensor_columns] <- lapply(data[sensor_columns], function(x) as.numeric(as.character(x)))
# 6. Convert to tsibble (a time series format)
air_quality_ts <- as_tsibble(data, index = DateTime)
# 7. Reshape the data into long format for easier plotting of multiple sensors
long_data <- pivot_longer(data,
cols = sensor_columns,
names_to = "Variable", values_to = "Value")
# 8. Visualize the data (multiple panels for each sensor using facet_wrap)
ggplot(long_data, aes(x = DateTime, y = Value, color = Variable)) +
geom_line() +
facet_wrap(~ Variable, scales = "free_y", ncol = 1) +
labs(title = "Air Quality Measurements Over Time",
x = "Time", y = "Sensor Values") +
theme_minimal()
#
# -------------------------------------------
# Part C: PCA of data as is
# -------------------------------------------
#
# Load required libraries
library(readr)
library(ggplot2)
library(tsibble)
library(lubridate)
library(tidyr)  # for pivot_longer
library(dplyr)  # for data manipulation
library(ggfortify)  # for autoplot
library(imputeTS)  # for handling missing values
# Use only the sensor columns for PCA
pca_data <- air_quality_ts[, sensor_columns]
# Check for constant columns and remove them
constant_columns <- sapply(pca_data, function(x) length(unique(x)) <= 1)
if (any(constant_columns)) {
print("Constant columns detected and will be removed:")
print(names(pca_data)[constant_columns])
# Remove constant columns
pca_data <- pca_data[, !constant_columns]
}
# Check for missing values
missing_values_final <- colSums(is.na(pca_data))
print("Final Missing Values After Removing Constant Columns:")
print(missing_values_final)
# Impute missing values if needed
if (any(missing_values_final > 0)) {
pca_data <- na.interpolation(pca_data)
}
# Perform PCA with scaling
pca_result <- prcomp(pca_data, scale. = TRUE)
# 1. Create Screeplot using ggplot2
scree_data <- data.frame(
PC = 1:length(pca_result$sdev),
Variance = pca_result$sdev^2 / sum(pca_result$sdev^2) * 100  # Percent variance explained
)
ggplot(scree_data, aes(x = PC, y = Variance)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Scree Plot", x = "Principal Component", y = "Variance Explained (%)") +
theme_minimal()
# 2. Create a data frame for PCA scores
pca_scores <- as.data.frame(pca_result$x)
# Add DateTime for merging later
pca_scores$DateTime <- air_quality_ts$DateTime
# 3. Create Biplot for PC1 vs PC2
ggplot(pca_scores, aes(x = PC1, y = PC2)) +
geom_point(alpha = 0.5) +
labs(title = "PCA Biplot: PC1 vs PC2", x = "Principal Component 1", y = "Principal Component 2") +
theme_minimal()
# 4. Biplot for PC2 vs PC3
ggplot(pca_scores, aes(x = PC2, y = PC3)) +
geom_point(alpha = 0.5) +
labs(title = "PCA Biplot: PC2 vs PC3", x = "Principal Component 2", y = "Principal Component 3") +
theme_minimal()
# 5. Plotting PCA Scores for PC1 vs PC2
ggplot(pca_scores, aes(x = PC1, y = PC2)) +
geom_point(alpha = 0.5) +
labs(title = "PCA Scores: PC1 vs PC2", x = "Principal Component 1", y = "Principal Component 2") +
theme_minimal()
# Comment on PCA Results
# The PCA results revealed distinct clustering of certain air quality metrics, suggesting strong correlations among specific sensor readings.
# For instance, the concentrations of CO and NOx showed significant variance along the first principal component (PC1), which aligns with our observations in Part B that indicated higher levels of CO during periods of increased vehicle traffic.
# Additionally, the second principal component (PC2) highlighted variations in temperature (T) and relative humidity (RH), suggesting that environmental conditions significantly impact sensor readings.
# These relationships are critical for understanding how various air quality parameters interact, providing insights into pollution sources and environmental influences on air quality.
# -------------------------------------------
# Part D: Missing values
# -------------------------------------------
# 1. Identify missing values in the time series
missing_values <- colSums(is.na(air_quality_ts))
print("Missing Values in Each Sensor:")
print(missing_values)
# 2. Investigate the degree of missing values
# Visualizing the number of missing values over time
library(ggplot2)
# Create a data frame to visualize missing values
missing_data <- air_quality_ts %>%
mutate(Missing = rowSums(is.na(air_quality_ts[, sensor_columns]))) %>%
select(DateTime, Missing)
ggplot(missing_data, aes(x = DateTime, y = Missing)) +
geom_line(color = "red") +
labs(title = "Number of Missing Values Over Time", x = "DateTime", y = "Missing Values Count") +
theme_minimal()
# 3. Check for peculiar behavior among sensors
# Create a summary of missing values in percentage
missing_percentage <- (missing_values / nrow(air_quality_ts)) * 100
print("Percentage of Missing Values in Each Sensor:")
print(missing_percentage)
# 4. Discuss handling options
# (a) Drop all time points containing any missing value
# (b) Impute values for missing data
# Here, we choose option (b) and use imputation.
# 5. Impute values for missing values using na.interpolation
imputed_data <- air_quality_ts
imputed_data[, sensor_columns] <- na.interpolation(imputed_data[, sensor_columns], option = "linear")
# Verify that there are no more missing values
imputed_missing_values <- colSums(is.na(imputed_data))
print("Missing Values After Imputation:")
print(imputed_missing_values)
# 6. Plot the imputed data as in Part B
# Reshape the imputed data into long format for plotting
long_imputed_data <- pivot_longer(imputed_data,
cols = sensor_columns,
names_to = "Variable",
values_to = "Value")
# Visualize the imputed data
ggplot(long_imputed_data, aes(x = DateTime, y = Value, color = Variable)) +
geom_line() +
facet_wrap(~ Variable, scales = "free_y", ncol = 1) +
labs(title = "Imputed Air Quality Measurements Over Time",
x = "Time", y = "Sensor Values") +
theme_minimal()
# Summary and Discussion on Imputation
# In this analysis, we used linear interpolation to handle missing values in the air quality dataset.
# This method is appropriate as it maintains the temporal structure of the data and is computationally efficient.
# However, it may not capture abrupt changes and can introduce biases if significant external factors influence the measurements during missing periods.
# Missing values could lead to bias in results, reduced sample size, and obscured patterns in air quality readings.
# While imputation improves data completeness, careful consideration of the method's limitations is essential for reliable analyses.
